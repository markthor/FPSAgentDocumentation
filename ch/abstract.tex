%!TEX root = ../preamble.tex

\begin{abstract}
This project investigates the potential of combining deep learning and neuroevolution in the context of a simple first person shooter (FPS) game to produce artificial intellegence capable of aiming and shooting based on raw pixel input. Deep learning is used for visual recognition, translating raw pixels to compact feature representations, while neuroevolution uses the feature representation to infer actions. Two types of feature representations are evaluated according to how precise they are approximated by deep learning, as well as how they support neuroevolution and the combination of the two. The results show limited success with combining the two techniques, as none of the feature representations perform well with both deep learning and neuroevolution. One of the feature representations is approximated very well using deep learning, which correctly predicts the position of targets that are hardly noticeable. The other feature representation is based of gradient descent with linear regression and while it shows promising results, the learning process and topology of the convolutional neural network is not optimised enough to reduce the error to a level that can adequately support the network evolved with neuroevolution. While neuroevolution produces agents capable of aiming and shooting well, their ability to generalise on other FPS games are heavily penalised by the simplicity of the FPS game in which they are trained. Overall, the results show that combining deep learning and neuroevolution is possible with the proposed approach, and it is likely that both feature representations can produce promising agents.
\end{abstract}