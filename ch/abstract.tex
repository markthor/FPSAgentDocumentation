\begin{abstract}

This project investigates the potential of combining deep learning and neuroevolution in the context of a simple FPS game to produce an AI capable of aiming and shooting based on raw pixel input. Deep learning is used for visual recognition, translating raw pixels to compact feature representations, while neuroevolution uses the feature representation to infer actions. Two types of feature representations are evaluated according to how precise they are approximated by deep learning as well as how they support neuroevolution and the combination of the two. The results show limited success with combining the two techniques, as none of the feature representations perform well with both deep learning and neuroevolution. Deep learning estimates one of the feature representations very well, detecting targets that are hardly noticeable. The other feature representation is based of gradient descent with linear regression and while it shows promising results, the learning process and topology of the artificial neural network is not optimised enough to reduce the error to a level that can adequately support the network evolved with neuroevolution. While neuroevolution produces agents capable of aiming and shooting well, their ability to generalise on other FPS games are heavily penalised by the simplicity of the FPS game in which they are trained. Overall, the results show that combining deep learning and neuroevolution is possible with the proposed approach, and it is likely that both feature representations can produce promising agents.

\end{abstract}