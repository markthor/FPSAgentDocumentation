%!TEX root = ../preamble.tex

\section{Discussion}
\label{sec:discussion}
The discussion is divided into three parts, respectively discussing the VRC, the AIC and the combination.

\subsection{The visual recognition component}
From the results in figure~\ref{fig:vpr-acc}, the CNNs estimating the VPR performed very well. The training examples that the networks failed to predict correctly were either when the target were in between partitions, or behind the weapon overlay, as seen in section \ref{sec:incorrectpredictions} of the appendix. The networks were able to correctly classify images, where we found it difficult to locate the target, as seen in figure~\ref{fig:hardprediction} and in section~\ref{sec:vdexamples} of the appendix and the varying lighting did not seem to cause incorrect predictions.

\begin{figure}[h]
	\begin{scriptsize}
		\sffamily
		\def\svgwidth{\textwidth}
		\input{img/hardprediction.pdf_tex}
	\end{scriptsize}
	\caption[Difficult VPR classification example]{The deep CNN estimating the VPR correctly predicts the class(green square) with a confidence of 55.7\%, with only four pixels of the target being visible. This example was not used for training. The feature maps produced from this example are included in section~\ref{sec:featuremaps-appendix} of the appendix.}
	\label{fig:hardprediction}
\end{figure}

The incorrect predictions of images were the target is present are generally cases were the target could be classified as being in either partition, depending on the exact location of the center of mass of the target. Consequently, such an incorrect prediction does not have a significant impact on an AIC using the incorrect classification to shoot and aim, as some of the target is present in the incorrect partition. These incorrections should therefore be viewed as a natural consequence of the vague classification definition, and not a failure of the optimisation of the model.

Optimising the model with gradient descent proved to be relatively trivial, performing adequately with two distinct network topologies, no regularisation and a very unbalanced distribution of classes. From these observations we conclude that the problem of estimating the VPR is well suited for deep learning. The network with 12 layers and the network with 6 layers performed equally well, but the deeper network did take approximately twice as long to train. However, we can not conclude that increasing the depth does not potentially increase performance if the VPR is applied to harder problems, and the observation should therefore not discourage the use of deeper networks to solve this type of problem. The distribution of classes of training examples is noticeably unbalanced, with more than a 100 times as many classes in the least represented class, as in the most represented class, as seen in table~\ref{tab:enemy-dist}. However, the unbalance does not seem to prevent the network from learning to recognize even the least represented classes. While it seems unlikely that the network can learn to recognize a class from less than 200 training examples, it is possible because the features recognized by the convolutional layer are similar for all the classes, as visualised in figure~\ref{fig:featuremapsvpr}. Hence, the training of less represented classes uses the convolutional filters learned from the more represented classes to optimise the fully connected layers.

The experimentation with training with a smaller volume of data showed that the 5,015 examples were insufficient to estimate the VPR to a sufficient accuracy, but the test set accuracy tendency in the results suggests, that significantly less than 130,000 training examples could yield almost the same accuracy. This suggests that a real world application of the VPR would require an amount of labelled data greater than 5,015, as we assume that targets in the real world are more visually varied and harder to detect than targets in this game.

The results in the performance paragraph of section~\ref{sec:results-angular-representation} shows varying success with estimating the AR. We observe that the topology of the network has an impact on the error of the horizontal angle, vertical angle and distance, especially when trained without visual distortion. The accuracy of target detection is not affected by the topology, which is not surprising, as it is a strictly easier problem than estimating the VPR. That the topology has a significant influence on the results, leads us to believe, that the problem can be solved with a smaller error if the network topology is improved. Increasing the amount of training data might also yield smaller errors.

The error of the deep network estimating the AR with visual distortion is more than twice as large as the counterpart without visual distortion. Recall that visual distortion both includes dynamic lighting, detailed textures and weapon overlay. This raises the question of how much each of these factors contribute to the error of the network. The visualised errors of figure~\ref{fig:aecollection}, shows that the network has a large error on some examples, where the weapon overlay does not even partially cover the target. Consequently, the two other factors complicates the target detection when estimating the AR. However, it is expected that the weapon overlay adds error in both angles and distance, even if the network functioned optimally. A target in the lower right corner covered by the weapon overlay would be impossible to detect for the VRC, and would in the worst case scenario have an absolute error of 1 in both angles with a theoretically optimal VRC.

The results of the network estimating the VPR with visual distortion indicates, that the network estimating the AR theoretically should be able to approximate the position of the target regardless of visual distortion. Section~\ref{sec:deeper-cnns} of the appendix shows experiments with even deeper networks, showing that the angular error can be further reduced by adding additional layers and neurons. Therefore it is assumed, that the inability of the network to estimate the AR with an adequate precision is due to insufficient tuning of the learning process, such as the volume or distribution of the training data, the topology of the network or hyper parameters of gradient descent. The network trained by Chenyi Chen et al.\cite{chen} is estimating features similar to the AR, and uses far more training data and trains for more iterations, which also indicates that the network presented by this project is far from optimal. The difference in quality of feature maps, visualised in section~\ref{sec:featuremaps} also indicates, that the convolutional layers of the network estimating the AR is not as functional as the convolutional layers of the network estimating the VPR, which solidifies this assumption. From a theoretical point of view, the difference in the quality of feature maps is not surprising, as the negative log-likelihood cost function optimises better than the euclidean loss cost function used for regression, as described and visualised by Xavier Glorot et al.\cite{DBLP:journals/jmlr/GlorotB10}. Training the network estimating the AR with the convolutional layers of a trained network estimating the VPR could possibly decrease the AR error.

\subsection{The action inferring component}
The results of training the AIC with neuroevolution presented in section~\ref{sec:neuroevolution-experiments-results} show that NEAT is capable of producing networks that can aim and shoot in a FPS game, using both the AR and the VPR. However, the applicability of these networks to other FPS games is heavily challenged by their tendency to learn from the particularities of the FPS game of the project. The distance to the target does not vary much, which the evolved networks exploit to implement reloading and shooting behaviour based on a fixed distance to the target, as the relationship between degrees rotated and the number of pixels that the target shifts on the screen is almost proportional. The network based on AR exploits the fact, that a new target spawns immediately after an elimination by reloading when the target is near the edge of the screen. This tends to result in a single reload as the time it takes to reload is greater than the time it takes to aim directly at the target. The AIC based on the VPR associates specific partitions with reloading. Consequently, none of the AICs learns generalisable reloading behaviour. Proper reloading behaviour requires either information about the number of shots left or long-term memory, none of which the AIC possess. The observations are therefore not surprising from a theoretical point of view.

The inability of the networks to develop human-like tap-fire is possibly because of the training duration. While we can conclude that 250 generations are not enough to develop this behaviour, we can not conclude that this approach is unable to develop tap-fire behaviour given enough time.

Neuroevolution evolves networks that are tailored to the task that they are evaluated on, and as our FPS game lacks variation, the networks does not learn much general applicable logic, except aiming and shooting without recoil. The best way to investigate the potential of NEAT in the domain of FPS games are to develop more varied evaluations that resembles modern FPS games. This is a significant shortcoming of the project, and optimisation of this area is recommended if the combination approach should be taken further.


\subsection{The pipeline}
The results in figure~\ref{fig:neat-cnn-comparison} show a significant difference between the reduction in performance from using a VRC with the AR and the VPR. The pipeline using a VRC estimating the AR clearly performs worse, and this observation corresponds with the performance evaluation of the individual VRCs in section~\ref{sec:results-angular-representation}. The estimation of the AR is far too inaccurate for the AIC to successfully infer an adequate action, and has its fitness reduced by 73.2\% when using the VRC. The weapon overlay covering the target reduces performance for both approaches, but this factor does not explain the entire 37.7\% fitness reduction from using a VRC with the VPR. From detailed examination of running the pipeline with a VRC estimating the VPR, we observed that the combination of low TPS and classification uncertainty when the target is in between partitions was a challenge. As the AIC is trained with the ground truths, assuming that the target is within a partition after a number of time steps given a specific AIC output is relatively safe. However, when the estimation of the VPR is inaccurate when the target is in between partitions, this assumption does not hold and can lead to unwanted behaviour. The consequence of this behaviour is amplified by the fact, that the AIC using the VPR associates specific partitions with reloading, penalising inaccurate partitioning classification. That the reduction in fitness can be attributed to this problem is substantiated by the increase in pipeline performance from reducing the look sensitivity, as seen in figure~\ref{fig:neat-cnn-comparison}.

The observations from the pipeline experiments harmonises well with the observations from the VRC experiments, and indicates that the VPR is easier estimated by deep learning than the AR.

Running the agent with the pipeline proved performance intensive, and the overall performance of the agent is definitely reduced by running with only 5 TPS. While the experiments failed to explore how well the combination could perform, they prove that it is possible for the combination to learn to aim and shoot with the VPR. We definitely believe that the approach can work for the AR, but the AR pipeline performance is not convincing enough to support any conclusions to this approach.

If this approach were to be implemented in a FPS game to control intelligent agents as game obstacles, the performance requirements would be a concern. Running multiple agents per human player along with the game would increase the performance requirement significantly. Using an AIC based on the AR with ground truths as input could be an alternative approach, which utilizes neuroevolution without deep learning and imposes less strict performance requirements on the game.

\subsection{Applications in real world robotics}
The modularity of the combined approach makes it easier applicable to real world robotics, such as military robots, drones and security camera and systems relying on identifying the position of targets based on visual input. The VRC can be combined with hand coded controllers, to create more reliable systems that are similar to the autonomous car driving agent developed by Chenyi Chen et al.\cite{chen}. Neuroevolution is challenging to apply to real world robotics, as the evaluation has to be faster than real time. Consequently, the robotics subject to neuroevolution has to be simulated virtually, which is further complicated by real world visual inputs. The abstraction provided by the feature representations makes this less complicated, as neuroevolution only has to interface with this representation. The VRC can theoretically be trained on labelled real world images, while the AIC can be trained without a visually realistic environment.