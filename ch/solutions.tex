%!TEX root = ../preamble.tex

\section{Solutions}
\label{sec:solutions}
Creating a fully functional visual FPS agent requires solutions to a range of different problems. To narrow the scope of the solution, the functionality of the proposed solutions is limited to only a subset of the required functionality to play a full-fledged FPS game, as Counter Strike or Quake. Developing a FPS agent capable of playing like a human player requires lots of different functionality as for example map navigation, adaptation of team role and identification of sound. The focus of the solution is aiming and shooting, and the proposed solutions only attempts to solve this problem. The problem includes dealing with weapon recoil, reloading properly and aiming and shooting at the target. The agent uses a single full automatic weapon.

\subsection{Actions}
The agent should be able to aim, shoot and reload. Therefore, the output of the AIC is turn horizontally, turn vertically, shoot and reload. The turn actions are analog, such that the greater the output, the faster it turns. Shoot and reload are binary actions, that triggers when the output is above a specific threshold. Shooting takes precedence over reload, and turning can be done while shooting or reloading.

\subsection{Granularity of control}
The frequency of which the AI makes decisions is a parameter that shapes the potential and performance requirements of the solution. The finest level of control is achieved by parsing every single frame of the game to infer an action. This is performance intensive, as the process of parsing the visual output through the VRC requires significant amount of computational resources. Using a control frequency lesser than the number of frames reduces the potential reaction speed of the agent and the overall smoothness of its behaviour. The approach of Michal Kempka et al.\cite{vizdoom} is also vision based, and repeats the chosen action for $k$ frames. We chose the same approach, as the flexibility of skipping frames reduces the hardware requirements. However, as we are unable to guarantee the FPS of the game and as the game framework does not allow control on a frame-by-frame basis, we refer to granularity of control as translates per second. Translates per second is the number of times the pipeline or AIC translates the state to an action per second.

Some of the functionality requirements of an agent capable of playing a game like Counter Strike might require higher level of control, such as deciding the long term strategy plan or navigating larger maps. This is not in the scope of the proposed solutions.

\subsection{Feature representations}
Recall that the feature representation is the integration point of the VRC and the AIC, and that it is the output of the VRC and the input of the AIC.
The feature representation of the visual state should allow the AIC to locate an enemy, aim and shoot it, while having as few dimensions as possible, as the evolution speed is a central concern. Additionally, the VRC has to be able to learn the features from training examples through supervised learning.

\subsubsection{Angular representation}
\label{sec:angular}
The angular feature representation unambiguously defines the position of the target on the screen. This representation has two angles, a distance and a binary output indicating whether the target is within sight. Figure \ref{fig:angular} shows the vertical angle, given by the angle between the current facing of the agent and a projection of the vector from the agent to the target. The projection is onto a plane determined by the vector of the current facing and the up-vector.
\begin{figure}[H]
    \centering
    	\begin{scriptsize}
		\sffamily
    	\includesvg[svgpath = img/, width = 0.7\textwidth]{verticalangle}
    	\end{scriptsize}
    \caption[Calculation of angles]{The relative vertical angle.}
    \label{fig:angular}
\end{figure}
\noindent
The horizontal angle is calculated in the same manner, except that the angle is calculated based on the projection of both vectors onto the horizontal plane. These two angles allows the AIC to infer the aiming directly. The distance is included to allow for changing shooting behaviour based on distance. For example, if the agent shoots a full automatic rifle at a long distance, it might be better to fire separate shots than using automatic fire. The binary indication of whether there is a target within sight, has the purpose of clarifying whether the angles reflects the position of a target, or just assumes default values. The scheme is visualised in figure~\ref{fig:angular}.
\begin{figure}[H]
    \centering
    	\begin{scriptsize}
		\sffamily
    	\includesvg[svgpath = img/, width = 1\textwidth]{angular}
    	\end{scriptsize}
    \caption[Angular representation of the visual state]{The vertical and horizontal angles define a position on the screen. The field of view is $65^\circ$ and the target is at a horizontal angle of $-17.17^\circ$ and a vertical angle of $15.05^\circ$ in this example.}
    \label{fig:angular}
\end{figure}

\subsubsection{Visual partitioning representation}
\label{sec:vpr}
The visual partitioning representation ambiguously indicates the position of the target on the screen. It defines the position of the target as a classification task, where each point on the screen belongs to a class bounded by a square as shown in figure \ref{fig:visualpartitioning}. 
\begin{figure}[H]
    \centering
    	\includesvg[svgpath = img/]{visualpartitioning}
    \caption[Visual partitioning representation]{The position of the target is interpreted as the square of which his centre of mass(marked by the blue dot) is located.}
    \label{fig:visualpartitioning}
\end{figure}
\noindent
As the target can be visually present in multiple squares, the correct square is defined as the square that contains his centre of mass. The partitioning is finer in the centre of the screen to allow for fine adjustments of the aim. The notation of the partitioning scheme is defined as the number of partitions on the vertical and horizontal axis of the whole screen, followed by the number of partitions on the horizontal or vertical axis of the centre of the previous partitioning. The scheme is exemplified in figure \ref{fig:visualpartitioningcompared}.

The feature representation is a sparse vector with a term for each partition. The term of the partition that contains the target is one, while all others are zero. If no partition contains the target, an additional term indicates the absence of a target.
\begin{figure}[H]
    \centering
    	\includesvg[svgpath = img/, width = 0.8\textwidth]{visualpartitioningcompared}
    \caption[Partitioning schemes]{The leftmost partitioning scheme is notated 3,3,3 and the rightmost is notated 5,3.}
    \label{fig:visualpartitioningcompared}
\end{figure}

\subsubsection{Optimal visual partitioning scheme}
It is necessary that a part of the target is present in the exact centre of the image, if the position of the target is classified as the centre partition. In that situation the agent would always, assuming no recoil, hit the enemy if there is an enemy in the centre partition and the agent shoots. Without that guarantee the task of consistently shooting the enemy becomes more difficult. The agent receives no feedback from misses, consequently if the centre square is to large, it can become impossible for the agent to learn to hit. The size of the agent is depending on distance, and this requirement is therefore depending on the distance that the agent should be able to hit at.

Assuming the target is 11 pixels wide and has a box-shaped hitbox\footnote{The projection of the target onto the screen that registers as a hit when shot at}, having a centre square of 11x11 pixels would fulfil the aforementioned requirement. If $6/11$ pixels is inside the centre square the enemy is considered to be inside that partition and since the sixth pixel is the centre pixel of the centre square, a part of the enemy is in the centre of the centre square - fulfilling the requirement.

A 5, 3 partitioning scheme would result in the centre partition being around 17 pixels wide, where it for a 3, 3, 3, partitioning scheme is approximately 9 pixels wide. There are 34 classes using a 5, 3 partitioning scheme, calculated as $(5*5-1)+(3*3)+1=34$ and 26 classes using a 3, 3, 3, partitioning scheme, calculated as $(3*3-1)+(3*3-1)+(3*3)+1=26$.

Since a 3, 3, 3 partitioning scheme results in fewer classes than a 5, 3 partitioning scheme, leading to faster training of the agent, and the resulting width of the centre partition is narrower, all experiments were done using a 3, 3, 3 partitioning scheme.




\subsubsection{Comparing the representations}
The feature representation of the VPR has a significantly larger number of dimensions than the AR, consequently slowing down evolution. The VPR is less detailed, as the precision of the AR is bound by the precision of the decimal used to represent the angle, while the precision of the VPR is bound by the width of the partitions. The AR allows the agent to choose shooting strategy based on distance and generally allows the agent to behave more smoothly. The large partitions of the VPR in the edges of the screen provide very ambiguous information about the position of the enemy, which makes it impossible for the agent to evolve smooth human-like aiming. If the agent was allowed to move or take strategic decisions, this lack of detail might reduce the potential of the agent furthermore. The AR allows the agent to aim precisely, which many FPS shooter games rewards by increasing the damage inflicted for hitting vulnerable areas on the target.

The only advantage of the VPR is that it is significantly easier to train a CNN to recognise this representation than the AR.

\subsection{The topology of the convolutional neural network}
The topology of the CNN has lots of different optimisation parameters, and as hyperparameter optimisation methods are based on trial and error, it takes time and computational resources to optimise. The project inevitably leaves room for better topologies that performs better, and the search for an efficient topology is not in the scope of this project. However, we impose some requirements on the topology. The stack of convolutional layers has to have a receptive field that can detect the target, as explained in section \ref{sec:topologies}. The width and height of the target is depending on distance, but it is approximately 10 pixels wide and 25 pixels high. Therefore, the topology of the network should be able to recognise visual features spanning at least 25 pixels. The network should have some depth, as it is often correlated with better performance\cite{christian}\cite{karen}, and use the rectifier activation function to reduce the vanishing gradient problem as described in section \ref{sec:vanishinggradient}.





































